import pickle
from datetime import datetime
from sklearn.linear_model import LinearRegression

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd
from matplotlib.ticker import FuncFormatter
from pprint import pprint


from main import create_all_features, abc_transform

plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 10
sns.set_style("whitegrid")


def normalize_feature_name(feature_name):
    """
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π
    """
    # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã, –∑–∞–ø—è—Ç—ã–µ, —Ç–æ—á–∫–∏ –∏ –ø—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
    normalized = (feature_name.lower()
                  .replace(' ', '_')
                  .replace(',', '')
                  .replace('.', '')
                  .replace('(', '')
                  .replace(')', ''))
    return normalized


class MMMVisualizer:
    def __init__(self, results_df):
        """
        results_df: DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ features, p-values, coef, A, B, C
        """
        self.results_df = results_df
        features = self.results_df['features'].tolist()
        features = list(map(lambda x: x.lower(), features))
        results_df['features'] = features

    def plot_saturation_curves(self, save_path='saturation_curves.png'):
        """
        –°—Ç—Ä–æ–∏—Ç –∫—Ä–∏–≤—ã–µ –Ω–∞—Å—ã—â–µ–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –º–µ–¥–∏–∞-–∫–∞–Ω–∞–ª–∞
        """
        media_channels = self.results_df[self.results_df['C'].notna()].copy()

        n_channels = len(media_channels)
        if n_channels == 0:
            print("–ù–µ—Ç –º–µ–¥–∏–∞-–∫–∞–Ω–∞–ª–æ–≤ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")
            return

        cols = min(3, n_channels)
        rows = (n_channels + cols - 1) // cols

        fig, axes = plt.subplots(rows, cols, figsize=(15, 5 * rows))

        if n_channels == 1:
            axes = [axes]
        elif rows == 1:
            axes = [axes] if cols == 1 else list(axes)
        else:
            axes = axes.flatten()

        fig.suptitle('–ö—Ä–∏–≤—ã–µ –Ω–∞—Å—ã—â–µ–Ω–∏—è –º–µ–¥–∏–∞-–∫–∞–Ω–∞–ª–æ–≤', fontsize=16, fontweight='bold')

        for idx, (_, row) in enumerate(media_channels.iterrows()):
            ax = axes[idx]

            A, B, C = row['A'], row['B'], row['C']
            channel_name = row['features'].replace('_abc', '').replace('_', ' ').title()

            max_spend = 1000
            spend_range = np.linspace(0, max_spend, 200)

            def abc_curve(spend, a, b, c):
                scaled = b * spend
                saturated = (c * scaled) / (1 + c * scaled)
                return saturated

            response = abc_curve(spend_range, A, B, C)

            ax.plot(spend_range, response, linewidth=3, color='#2E86AB', label='–ö—Ä–∏–≤–∞—è –æ—Ç–∫–ª–∏–∫–∞')
            ax.fill_between(spend_range, 0, response, alpha=0.3, color='#2E86AB')

            current_spend = 500
            current_response = abc_curve(current_spend, A, B, C)
            ax.scatter([current_spend], [current_response], color='red', s=100,
                       zorder=5, label='–¢–µ–∫—É—â–∏–π —É—Ä–æ–≤–µ–Ω—å')

            ax.set_title(f'{channel_name}\nA={A:.3f}, B={B:.3f}, C={C:.3f}',
                         fontweight='bold', pad=20)
            ax.set_xlabel('–ú–µ–¥–∏–∞-–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏', fontweight='bold')
            ax.set_ylabel('–ü—Ä–∏—Ä–æ—Å—Ç –ø—Ä–æ–¥–∞–∂', fontweight='bold')
            ax.grid(True, alpha=0.3)
            ax.legend()

            if C < 1:
                saturation_text = "–ë—ã—Å—Ç—Ä–æ–µ –Ω–∞—Å—ã—â–µ–Ω–∏–µ"
            elif C < 2:
                saturation_text = "–£–º–µ—Ä–µ–Ω–Ω–æ–µ –Ω–∞—Å—ã—â–µ–Ω–∏–µ"
            else:
                saturation_text = "–ú–µ–¥–ª–µ–Ω–Ω–æ–µ –Ω–∞—Å—ã—â–µ–Ω–∏–µ"

            ax.text(0.05, 0.95, saturation_text, transform=ax.transAxes,
                    bbox=dict(boxstyle="round,pad=0.3", facecolor="yellow", alpha=0.7),
                    verticalalignment='top', fontsize=9)

        for idx in range(n_channels, len(axes)):
            axes[idx].remove()

        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()

    def create_model_from_coefficients(self, transformed_data, target_col='sales',
                                       intercept=None, save_path=None):
        """
        –°–æ–∑–¥–∞–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥–æ—Ç–æ–≤—ã—Ö –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤ –∏ ABC –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

        Args:
            original_data: –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (DataFrame)
            coefficients_df: DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ features, p-values, coef, A, B, C
            target_col: –Ω–∞–∑–≤–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
            intercept: —Å–≤–æ–±–æ–¥–Ω—ã–π —á–ª–µ–Ω (–µ—Å–ª–∏ None, —Ä–∞—Å—Å—á–∏—Ç–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
            save_path: –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

        Returns:
            dict: model_data —Å –º–æ–¥–µ–ª—å—é, –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """

        print("–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏–∑ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤...")
        abc_params = {}

        for _, row in self.results_df.iterrows():
            feature_name = row['features'].lower()
            if pd.notna(row.get('A')) and pd.notna(row.get('B')) and pd.notna(row.get('C')):
                A, B, C = row['A'], row['B'], row['C']
                original_feature = feature_name.replace('_abc', '')

                if original_feature in transformed_data.columns:
                    original_values = transformed_data[original_feature].values
                    abc_transformed = abc_transform(original_values, A, B, C)
                    transformed_data[feature_name] = abc_transformed

                    abc_params[f'{original_feature}_A'] = A
                    abc_params[f'{original_feature}_B'] = B
                    abc_params[f'{original_feature}_C'] = C

                else:
                    print(f"–ò—Å—Ö–æ–¥–Ω–∞—è —Ñ–∏—á–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {original_feature}")
        # print('qwe', self.results_df['features'])
        # print(transformed_data.columns)
        features = self.results_df['features'].tolist()

        missing_features = [f for f in features if f not in transformed_data.columns]

        if missing_features:
            print(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {missing_features}")
            return None

        clean_data = transformed_data[features + [target_col]].dropna()
        X = clean_data[features].values
        y = clean_data[target_col].values
        coefficients = self.results_df['coef'].values

        print(f"–ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {len(clean_data)} –Ω–∞–±–ª—é–¥–µ–Ω–∏–π, {len(features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

        model = LinearRegression()
        model.coef_ = coefficients
        if intercept is None:
            # intercept = mean(y) - mean(X @ coef)
            predicted_without_intercept = X @ coefficients
            intercept = np.mean(y) - np.mean(predicted_without_intercept)

        model.intercept_ = intercept
        model.n_features_in_ = len(features)
        model.feature_names_in_ = np.array(features)

        y_pred = model.predict(X)
        r2_score = 1 - (np.sum((y - y_pred) ** 2) / np.sum((y - np.mean(y)) ** 2))
        mse = np.mean((y - y_pred) ** 2)
        rmse = np.sqrt(mse)

        print(f"üìà –ö–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏:")
        print(f"   R¬≤: {r2_score:.4f}")
        print(f"   RMSE: {rmse:.2f}")

        params = abc_params.copy()

        used_media = [f for f in features if '_abc' in f]
        used_price = [f for f in features if any(p in f.lower() for p in ['price', 'premium', 'discount'])]
        used_seasonal = [f for f in features if
                         any(s in f.lower() for s in ['spring', 'summer', 'autumn', 'winter', 'holiday', 'trend'])]
        used_other = [f for f in features if f not in used_media + used_price + used_seasonal]

        params.update({
            'used_media': used_media,
            'used_price': used_price,
            'used_seasonal': used_seasonal,
            'used_other': used_other,
            'intercept': intercept
        })

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        metadata = {
            'timestamp': timestamp,
            'creation_method': 'from_coefficients',
            'n_features': len(features),
            'target_col': target_col,
            'train_data_shape': clean_data.shape,
            'r2_score': r2_score,
            'rmse': rmse,
            'intercept': intercept,
            'feature_groups': {
                'media': used_media,
                'price': used_price,
                'seasonal': used_seasonal,
                'other': used_other
            },
            'abc_transformations': len([f for f in features if '_abc' in f])
        }

        model_data = {
            'model': model,
            'features': features,
            'params': params,
            'transformed_data': clean_data,
            'coefficients_df': self.results_df,
            'metadata': metadata,
            'abc_params': abc_params
        }

        if save_path:
            with open(save_path, 'wb') as f:
                pickle.dump(model_data, f)
            print(f"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {save_path}")

        return model_data

    def plot_real_contribution_over_time(self, df_data, model, save_path='real_contribution.png'):
        """
        –†–µ–∞–ª—å–Ω–∞—è –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è –ø—Ä–æ–¥–∞–∂ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        df_data: DataFrame —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∏ —Ñ–∏—á–∞–º–∏
        model: –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
        features: —Å–ø–∏—Å–æ–∫ —Ñ–∏—á, –∫–æ—Ç–æ—Ä—ã–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–æ–¥–µ–ª—å
        """
        features = self.results_df['features'].tolist()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å–µ —Ñ–∏—á–∏ –µ—Å—Ç—å –≤ –¥–∞–Ω–Ω—ã—Ö
        missing_features = [f for f in features if f not in df_data.columns]
        if missing_features:
            print(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ–∏—á–∏: {missing_features}")
            return

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        X = df_data[features].values
        coefficients = model.coef_
        intercept = model.intercept_

        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –≤–∫–ª–∞–¥ –∫–∞–∂–¥–æ–π —Ñ–∏—á–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞
        contributions = {}

        # –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∞ (–±–∞–∑–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å)
        contributions['–ö–æ–Ω—Å—Ç–∞–Ω—Ç–∞'] = [intercept] * len(df_data)

        # –í–∫–ª–∞–¥ –∫–∞–∂–¥–æ–π —Ñ–∏—á–∏ = –∑–Ω–∞—á–µ–Ω–∏–µ_—Ñ–∏—á–∏ * –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç
        for i, feature in enumerate(features):
            feature_contribution = df_data[feature].values * coefficients[i]
            clean_name = feature.replace('_abc', '').replace('_', ' ').title()
            contributions[clean_name] = feature_contribution

        # –í—Ä–µ–º–µ–Ω–Ω–∞—è –æ—Å—å
        if 'Week' in df_data.columns:
            x = df_data['Week']
            x_label = '–ù–µ–¥–µ–ª–∏'
        else:
            x = range(len(df_data))
            x_label = '–ü–µ—Ä–∏–æ–¥'

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è stackplot
        labels = list(contributions.keys())
        y_data = list(contributions.values())

        # –¶–≤–µ—Ç–∞
        mycolors = ['lightblue', 'tab:green', 'tab:red', 'tab:orange', 'tab:brown',
                    'tab:pink', 'tab:olive', 'tab:cyan', 'tab:purple', 'tab:gray',
                    'darkblue', 'darkgreen', 'darkred', 'darkorange']

        # –û–±—Ä–µ–∑–∞–µ–º –ø–æ–¥ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏—á–µ–π
        colors = mycolors[:len(labels)]

        # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ–∏–∫
        fig, ax = plt.subplots(1, 1, figsize=(16, 9), dpi=80)

        # –°—Ç—Ä–æ–∏–º stackplot
        ax.stackplot(x, *y_data, labels=labels, colors=colors, alpha=0.8)

        # –î–æ–±–∞–≤–ª—è–µ–º –ª–∏–Ω–∏—é —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–¥–∞–∂ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        if 'Sales' in df_data.columns:
            actual_sales = df_data['Sales'].values
            predicted_sales = np.sum(y_data, axis=0)

            ax.plot(x, actual_sales, 'k-', linewidth=3, label='–§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–¥–∞–∂–∏', alpha=0.9)
            ax.plot(x, predicted_sales, 'r--', linewidth=2, label='–ú–æ–¥–µ–ª—å–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑', alpha=0.9)

        # –û—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –≤ —Å—Ç–∏–ª–µ –ø—Ä–∏–º–µ—Ä–∞
        ax.set_title('–î–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è –ø—Ä–æ–¥–∞–∂ –ø–æ —Ñ–∞–∫—Ç–æ—Ä–∞–º –≤–æ –≤—Ä–µ–º–µ–Ω–∏\n(–†–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)',
                     fontsize=18, fontweight='bold')
        ax.set_xlabel(x_label, fontsize=14)
        ax.set_ylabel('–ü—Ä–æ–¥–∞–∂–∏', fontsize=14)

        # –õ–µ–≥–µ–Ω–¥–∞
        ax.legend(fontsize=10, ncol=3, loc='upper left')

        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Å–µ–π
        if len(x) > 20:
            step = len(x) // 10
            plt.xticks(x[::step], fontsize=10, rotation=45)
        else:
            plt.xticks(x, fontsize=10, rotation=45)

        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Å–∏ Y
        ax.yaxis.set_major_formatter(FuncFormatter(lambda x, p: f'{x:,.0f}'))

        # –°—Ç–∏–ª—å –∫–∞–∫ –≤ –ø—Ä–∏–º–µ—Ä–µ - –æ–±–ª–µ–≥—á–∞–µ–º –≥—Ä–∞–Ω–∏—Ü—ã
        plt.gca().spines["top"].set_alpha(0)
        plt.gca().spines["bottom"].set_alpha(.3)
        plt.gca().spines["right"].set_alpha(0)
        plt.gca().spines["left"].set_alpha(.3)

        # –°–µ—Ç–∫–∞
        ax.grid(True, alpha=0.3)
        ax.set_axisbelow(True)

        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()

        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤–∫–ª–∞–¥–æ–≤
        print(f"\n –°–†–ï–î–ù–ò–ï –í–ö–õ–ê–î–´ –ü–û –§–ê–ö–¢–û–†–ê–ú:")
        print(f"{'‚îÄ' * 50}")

        total_avg_contribution = {}
        for name, values in contributions.items():
            avg_contribution = np.mean(values)
            total_avg_contribution[name] = avg_contribution
            print(f"{name:<25}: {avg_contribution:>10,.0f}")

        total = sum(total_avg_contribution.values())
        print(f"{'–ò–¢–û–ì–û':<25}: {total:>10,.0f}")

        if 'Sales' in df_data.columns:
            actual_avg = df_data['Sales'].mean()
            print(f"{'–§–∞–∫—Ç (—Å—Ä–µ–¥–Ω–µ–µ)':<25}: {actual_avg:>10,.0f}")
            print(f"{'–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ':<25}: {total - actual_avg:>10,.0f}")

    def plot_feature_elasticity(self, model, transformed_data, save_path='feature_elasticity.png'):
        """
        –ì—Ä–∞—Ñ–∏–∫ —ç–ª–∞—Å—Ç–∏—á–Ω–æ—Å—Ç–∏ —Ñ–∞–∫—Ç–æ—Ä–æ–≤ (% –∏–∑–º–µ–Ω–µ–Ω–∏–µ Y –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ X –Ω–∞ 1%)
        """
        features = self.results_df['features'].tolist()
        coefficients = model.coef_

        elasticities = []

        target_col = self.target_col if hasattr(self, 'target_col') else 'sales'
        mean_y = np.mean(transformed_data[target_col])

        for i, feature in enumerate(features):
            if feature in transformed_data.columns:
                coef = coefficients[i]
                mean_x = np.mean(transformed_data[feature])

                # –≠–ª–∞—Å—Ç–∏—á–Ω–æ—Å—Ç—å = (dY/dX) * (X/Y) = coef * (mean_X / mean_Y)
                if mean_y != 0 and mean_x != 0:
                    elasticity = coef * (mean_x / mean_y)

                    clean_name = feature.replace('_abc', '').replace('_', ' ').title()
                    elasticities.append((clean_name, elasticity, coef))

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∞–±—Å–æ–ª—é—Ç–Ω–æ–π —ç–ª–∞—Å—Ç–∏—á–Ω–æ—Å—Ç–∏
        elasticities.sort(key=lambda x: abs(x[1]), reverse=True)

        names = [x[0] for x in elasticities]
        elast_values = [x[1] for x in elasticities]
        colors = ['tab:green' if v > 0 else 'tab:red' for v in elast_values]

        fig, ax = plt.subplots(1, 1, figsize=(12, 8), dpi=80)

        bars = ax.barh(names, [abs(v) for v in elast_values], color=colors, alpha=0.8)

        for i, (bar, val) in enumerate(zip(bars, elast_values)):
            width = bar.get_width()
            ax.text(width + max([abs(v) for v in elast_values]) * 0.01,
                    bar.get_y() + bar.get_height() / 2,
                    f'{val:+.3f}', ha='left', va='center', fontweight='bold')

        ax.set_title('–≠–ª–∞—Å—Ç–∏—á–Ω–æ—Å—Ç—å —Ñ–∞–∫—Ç–æ—Ä–æ–≤\n(% –∏–∑–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–æ–¥–∞–∂ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ —Ñ–∞–∫—Ç–æ—Ä–∞ –Ω–∞ 1%)',
                     fontsize=16, fontweight='bold')
        ax.set_xlabel('|–≠–ª–∞—Å—Ç–∏—á–Ω–æ—Å—Ç—å|')

        ax.spines["top"].set_alpha(0)
        ax.spines["bottom"].set_alpha(.3)
        ax.spines["right"].set_alpha(0)
        ax.spines["left"].set_alpha(.3)
        ax.grid(True, alpha=0.3, axis='x')

        from matplotlib.patches import Patch
        legend_elements = [
            Patch(facecolor='tab:green', label='–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–∞—è —ç–ª–∞—Å—Ç–∏—á–Ω–æ—Å—Ç—å'),
            Patch(facecolor='tab:red', label='–û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–∞—è —ç–ª–∞—Å—Ç–∏—á–Ω–æ—Å—Ç—å')
        ]
        ax.legend(handles=legend_elements, loc='lower right')

        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()

        return elasticities


params = pd.read_excel('model_params.xlsx')

data = pd.read_csv('data.csv', sep=';', encoding='utf-8')
data['Week'] = pd.to_datetime(data['Week'], format='%d.%m.%Y')
data = create_all_features(data.copy())
# print(data.columns)

normalized_columns = list(map(lambda x: normalize_feature_name(x), data.columns))
data.columns = normalized_columns
# print(data.columns)
visualizer = MMMVisualizer(params)

# –°—Ç—Ä–æ–∏–º –≤—Å–µ –≥—Ä–∞—Ñ–∏–∫–∏
visualizer.plot_saturation_curves()
model = visualizer.create_model_from_coefficients(data)

visualizer.plot_real_contribution_over_time(data, model['model'])
# visualizer.plot_feature_elasticity(model['model'], data)

print(model)
